{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fd8284c7",
      "metadata": {
        "id": "fd8284c7"
      },
      "source": [
        "# Road Traffic Vehicle Counting Exam"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e8c1a5",
      "metadata": {
        "id": "90e8c1a5"
      },
      "source": [
        "In this exam, you will use the YOLO (You Only Look Once) object detection model to analyze a video of road traffic. Your primary task is to count the number of vehicles exiting the road at each of the four exits (located at the top, bottom, left, and right of the frame). The video for this task is provided at `Datasets/YOLO_Exam_Video.mp4`.\n",
        "\n",
        "## Objectives\n",
        "- Load and process the video using OpenCV.\n",
        "- Utilize the YOLO model to detect vehicles in each frame.\n",
        "- Manipulate the video frames using OpenCV.\n",
        "- Track vehicles as they move across the video frames.\n",
        "- Count the number of vehicles exiting via the top street.\n",
        "- Count the number of vehicles exiting via the bottom street.\n",
        "- Count the number of vehicles exiting via the left street.\n",
        "- Count the number of vehicles exiting via the right street.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7269b0e",
      "metadata": {
        "id": "c7269b0e"
      },
      "source": [
        "## Setup Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd3bce8",
      "metadata": {
        "id": "2fd3bce8"
      },
      "source": [
        "Before you begin, ensure you have the necessary libraries installed. You will need `opencv`, and `ultralytics` among others.\n",
        "If these are not installed, you should install them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e48a05c4",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "e48a05c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d251d8c4-ac8d-4feb-fc1c-892777d5c5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.85-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m980.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.6-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.85-py3-none-any.whl (872 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.3/872.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.2.85 ultralytics-thop-2.0.6\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install ultralytics\n",
        "! pip install torch torchvision torchaudio\n",
        "! pip install  opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a69c2ac2",
      "metadata": {
        "id": "a69c2ac2"
      },
      "source": [
        "## Load the YOLO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "145d70fc",
      "metadata": {
        "id": "145d70fc"
      },
      "source": [
        "You will first need to load the YOLO model, there is a custom model for this exam called `YOLO_Model.pt` under Datasets file ⚠️ PLEASE USE THIS MODEL AND DO NOT USE ANY OTHER MODEL ⚠️.\n",
        "Write the code to load the YOLO model below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7e580e4a",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "7e580e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "collapsed": true,
        "outputId": "f9a8d508-6661-41da-fddd-d586819be037"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8d0ad93eedba>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/YOLO_Model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Continue with default YOLO initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     def __call__(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mattempt_load_one_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;34m\"\"\"Loads a single model weights.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ema\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    782\u001b[0m             },\n\u001b[1;32m    783\u001b[0m         ):\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights_only\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_torch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0moverall_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('/content/YOLO_Model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(model)llمالها فايدة  بس اشيك على المودل"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xhl3ZFgE4dU",
        "outputId": "9c643b53-e65c-473f-cfcb-2ca6f9bdf0fb"
      },
      "id": "8Xhl3ZFgE4dU",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLO(\n",
            "  (model): DetectionModel(\n",
            "    (model): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Conv(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (4): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-5): 6 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Conv(\n",
            "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (6): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-5): 6 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (7): Conv(\n",
            "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (8): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (9): SPPF(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (11): Concat()\n",
            "      (12): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (14): Concat()\n",
            "      (15): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (16): Conv(\n",
            "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (17): Concat()\n",
            "      (18): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (19): Conv(\n",
            "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (20): Concat()\n",
            "      (21): C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-2): 3 x Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (22): Detect(\n",
            "        (cv2): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1-2): 2 x Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (cv3): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(320, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1-2): 2 x Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(320, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (dfl): DFL(\n",
            "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf691ac8",
      "metadata": {
        "id": "cf691ac8"
      },
      "source": [
        "## Prepare the Video Capture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw9RSvKCdonK"
      },
      "source": [
        "Create a variable to capture the video frames, you can use `cv2.VideoCapture()` to achive this."
      ],
      "id": "Nw9RSvKCdonK"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "81cfbca1",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "81cfbca1"
      },
      "outputs": [],
      "source": [
        "video_path = '/content/YOLO_Video.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)"
      ],
      "metadata": {
        "id": "mHyxanbfF9Dg"
      },
      "id": "mHyxanbfF9Dg",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "48757309",
      "metadata": {
        "id": "48757309"
      },
      "source": [
        "## Get Video Information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4f5d5bc",
      "metadata": {
        "id": "b4f5d5bc"
      },
      "source": [
        "You can use `cv2` library to get these information fro the `VideoCapture()` variable you created to extract these information:\n",
        "* `height`: Video's height.\n",
        "* `width`: Video's width.\n",
        "* `fps`: Video's frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cb8e5ceb",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "cb8e5ceb"
      },
      "outputs": [],
      "source": [
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Video width : {width} pixels')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyHZtm78HfuO",
        "outputId": "73050393-6c8d-48ff-8faf-093e5b053e13"
      },
      "id": "JyHZtm78HfuO",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video width : 1920 pixels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heigh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
      ],
      "metadata": {
        "id": "4A9QNspQHxZA"
      },
      "id": "4A9QNspQHxZA",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Video heigh {heigh} pixels')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSo1jYb9IHVN",
        "outputId": "7ee32f06-af49-421e-c75f-fcab80ae0760"
      },
      "id": "eSo1jYb9IHVN",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video heigh 1080 pixels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fps = cap.get(cv2.CAP_PROP_FPS)"
      ],
      "metadata": {
        "id": "p3Tl9_y2IgWx"
      },
      "id": "p3Tl9_y2IgWx",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' frames per second fbs {fps}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8zqvh0CIupW",
        "outputId": "f04f7483-c916-4bcf-cf99-ae12cde4c87e"
      },
      "id": "Q8zqvh0CIupW",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " frames per second fbs 29.97002997002997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f241495",
      "metadata": {
        "id": "3f241495"
      },
      "source": [
        "## Prepare Video Writer to Store the Output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef61a34",
      "metadata": {
        "id": "9ef61a34"
      },
      "source": [
        "Create a variable that uses `cv2.VideoCapture()` to save the video with the bounding boxes, specified Region of Interest rectangle (ROI) and the counted vehicles on each sides. You will need to make the video with the same `fps`, `width`, `height`, and specify the codec and output path of the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "449562c2",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "449562c2"
      },
      "outputs": [],
      "source": [
        "#output_path = '/content/YOLO_Video.mp4' لا تحطها في نفس الفايل\n",
        "output_path = '/content/output_video_with_predictions.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc,29.97002997002997 , (1920, 1080))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fourcc =cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path,fourcc,fps,(width,heigh))"
      ],
      "metadata": {
        "id": "9KbPlh54Jh3W"
      },
      "id": "9KbPlh54Jh3W",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "31e882a2",
      "metadata": {
        "id": "31e882a2"
      },
      "source": [
        "## Expermint to get the `(x1, y1, x2, y2)` of the ROI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b6e6d97",
      "metadata": {
        "id": "3b6e6d97"
      },
      "source": [
        "### Hint\n",
        "When defining the Regions of Interest (ROIs) for detecting vehicles exiting the road, consider the coordinates that outline the relevant areas. These coordinates can be specified as `(x1, y1, x2, y2)`, where `(x1, y1)` is the top-left corner and `(x2, y2)` is the bottom-right corner of the rectangle.\n",
        "\n",
        "Experiment with different coordinates to accurately cover the streets where vehicles exit. Visualize these ROIs by drawing rectangles on a frame of the video and adjust the coordinates as needed until you capture the desired areas effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "68f46e81",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "68f46e81"
      },
      "outputs": [],
      "source": [
        "# define the rol\n",
        "rois = [\n",
        "    (50,100,400,300),\n",
        "    (450,100,800,300)\n",
        "\n",
        "]\n",
        "while cap.isOpened():\n",
        "  ret,feame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "    # drow rol\n",
        "    for (X1,y1,X2,y2) in rois:\n",
        "      cv2.rectangle(frame, (X1,y1),(X2,y2),(0,255,0),2)\n",
        "      # display\n",
        "      cv2.imshow('ROIs',frame)\n",
        "\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "       break\n",
        "      cap.release()\n",
        "      cv2.destroyAllWindows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "067dbc12",
      "metadata": {
        "id": "067dbc12"
      },
      "source": [
        "## Process Video Frames and Identify Vehicles Left the Road Form Each Street"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa695d88",
      "metadata": {
        "id": "aa695d88"
      },
      "source": [
        "For each frame in the video, use the YOLO model to detect and track vehicles. You will need to write a loop that processes each frame and applies the YOLO model.\n",
        "\n",
        "In each frame, after detecting the vehicles, determine whether they exited the road via the top, bottom, left, or right street. You can use the positions of the bounding boxes provided by YOLO to do this.\n",
        "\n",
        "- The video should display bounding boxes around the detected objects.\n",
        "- The video should display your name on the top.\n",
        "- It should display the calculated center of each vehicle.\n",
        "- The video should display the confidence score, alongside the object ID and class ID of each detected and tracked object.\n",
        "- The video should display the rectangles representing the regions where you count the vehicles that have crossed and exited.\n",
        "- The video should display the number of vehicles that exited via the top street.\n",
        "- The video should display the number of vehicles that exited via the bottom street.\n",
        "- The video should display the number of vehicles that exited via the left street.\n",
        "- The video should display the number of vehicles that exited via the right street."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "877d1d56",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "877d1d56"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTDebigofg_T",
        "outputId": "8650bc47-e076-4f90-a3be-20b45280ba1f"
      },
      "id": "BTDebigofg_T",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('/content/YOLO_Model.pt')\n",
        "\n",
        "cap = cv2.VideoCapture('/content/output_video_with_predictions.mp4')\n",
        "\n",
        "rois = [\n",
        "    (50, 100, 400, 300),\n",
        "    (450, 100, 800, 300)\n",
        "]\n",
        "\n",
        "exit_counts = {'top': 0, 'bottom': 0, 'left': 0, 'right': 0}\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    height, width, _ = frame.shape\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    boxes, confidences, class_ids = [], [], [] # المصدر>>(https://www.youtube.com/watch?v=8Jq3h2a-0yA)\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x, center_y, w, h = (detection[0:4] * np.array([width, height, width, height])).astype('int')\n",
        "                x1, y1 = int(center_x - w / 2), int(center_y - h / 2)\n",
        "                boxes.append([x1, y1, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "                indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    for i in indices:\n",
        "        i = i[0]\n",
        "        box = boxes[i]\n",
        "        (x, y, w, h) = box\n",
        "        center_x = x + w // 2\n",
        "        center_y = y + h // 2\n",
        "\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'ID: {class_ids[i]} | Conf: {confidences[i]:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "        cv2.circle(frame, (center_x, center_y), 5, (255, 0, 0), -1)\n",
        "        if center_y < 100:\n",
        "            exit_counts['top'] += 1\n",
        "        elif center_y > height - 100:\n",
        "            exit_counts['bottom'] += 1\n",
        "        elif center_x < 100:\n",
        "            exit_counts['left'] += 1\n",
        "        elif center_x > width - 100:\n",
        "            exit_counts['right'] += 1\n",
        "\n",
        "    for (x1, y1, x2, y2) in rois:\n",
        "         cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "         cv2.putText(frame, f'Exits - Top: {exit_counts[\"top\"]}, Bottom: {exit_counts[\"bottom\"]}, Left: {exit_counts[\"left\"]}, Right: {exit_counts[\"right\"]}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
        "    cv2.putText(frame, 'car', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "\n",
        "    cv2.imshow('Vehicle Detection', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "trjMYBi8Z0eA"
      },
      "id": "trjMYBi8Z0eA",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/output_video_with_predictions.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EeTpi7JbeuDi",
        "outputId": "4a142dc4-c1d4-49c6-e2f7-aa2ce1806a1c"
      },
      "id": "EeTpi7JbeuDi",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f0ccd106-b3f4-4d71-89c6-c44570639607\", \"output_video_with_predictions.mp4\", 258)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " ! pip install -q mediapy"
      ],
      "metadata": {
        "id": "Nw33QMw4kJ7V"
      },
      "id": "Nw33QMw4kJ7V",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapy as media\n",
        "faile =('/content/output_video_with_predictions.mp4')"
      ],
      "metadata": {
        "id": "igMG16GDkef8"
      },
      "id": "igMG16GDkef8",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "71d3083e",
      "metadata": {
        "id": "71d3083e"
      },
      "source": [
        "## Save and Submit Your Work"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae5e33ac",
      "metadata": {
        "id": "ae5e33ac"
      },
      "source": [
        "Submit both the notebook and the output video"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}